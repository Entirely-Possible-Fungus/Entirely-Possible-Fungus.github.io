{
    "missions": {
        "columns": {
            "id": "INT PRIMARY KEY",
            "title": "STRING",
            "description": "STRING",
            "hint": "STRING",
            "difficulty": "INT",
            "points": "INT",
            "timeLimit": "INT",
            "timerEnabled": "BOOLEAN",
            "successMessage": "STRING",
            "dbAlias": "STRING",
            "validationCriteria": "JSON",
            "mapDetails": "JSON",
            "nextMissionId": "INT"
        },
        "data": [
            {
                "id": 0,
                "title": "Tutorial: Mounting Databases",
                "description": "Boss: Analyst #6023, welcome to the Human Data Interface Program. Your primary objective is to analyze and assist the civilization on Planet UID-398 ('Earth'). Before direct engagement with their complex societal data, you must master their fundamental 'SQL' data access protocols. Your first task is elementary but crucial: learn to connect to their data archives, a process they term 'mounting a database'. Consider this your system initiation.<br><br>Here's the protocol:</p><ol><li>Access the <strong>DB REGISTRY</strong> interface module.</li><li>Locate and activate the <strong>MOUNT</strong> sequence for the <strong>mission_control</strong> data archive.</li><li>Securely close the <strong>DB Registry</strong> interface.</li></ol><p><strong>This procedure will grant you initial access to the mission control servers.</strong>\n\nSuccessful execution will allow you to proceed to your next briefing, where you'll learn to issue direct data queries.<br>Should you encounter any difficulties, consult the provided hint parameters or the full solution protocols. There are no demerits for utilizing these resources at this stage; familiarization is key.</p>",
                "hint": "Click the DB REGISTRY button, find mission_control, click MOUNT, then close the registry panel.",
                "solution": "Click the DB REGISTRY button, find mission_control, click MOUNT, then close the registry panel.",
                "difficulty": 1,
                "points": 25,
                "timeLimit": 300,
                "timerEnabled": false,
                "successMessage": "Excellent! You've mounted your first database. Now you can access the mission_control database to see what we have available. Click the green button below to continue on.",
                "dbAlias": "mission_control",
                "validationCriteria": {
                    "databaseMounted": true,
                    "requiredDatabase": "mission_control"
                },
                "mapDetails": {
                    "showOnMap": false
                },
                "nextMissionId": 1
            },
            {
                "id": 1,
                "title": "Tutorial: First Query",
                "description": "Boss: Commendable work on establishing that connection, Analyst #6023. You've successfully linked to the `mission_control` archive. Now, let's verify your ability to extract intelligence. Your next task is to execute your first 'SQL query'. This is the standard method humans use to request information from their databases.<br><br>\n\nObserve the <strong>SQL Console</strong>: This is your command interface for constructing and transmitting these queries.\n\n<strong>Your first data extraction task:</strong>\n\n<code class='pixel-inline-code'>SELECT * FROM missions;</code>\n\n<strong>The Boss deciphers the command:</strong>\n<ul>\n<li><code>SELECT *</code> - This syntax instructs the system to retrieve all available data fields.</li>\n<li><code>FROM missions</code> - This specifies the 'missions' data table as the source of information.</li>\n<li><code>;</code> - This symbol signifies the termination of the command sequence.</li>\n</ul>\n\nExecuting this will reveal all available missions within this training database. The retrieved data will be displayed in the Results Area below. Understanding their mission structure is the first step to anticipating their actions.",
                "hint": "Type <code>SELECT * FROM missions;</code> in the SQL console and click Execute to see all the missions.",
                "solution": "SELECT * FROM missions;",
                "difficulty": 1,
                "points": 25,
                "timeLimit": 300,
                "timerEnabled": false,
                "successMessage": "Great job! You've run your first SQL query and can now see all available missions in the database.",
                "dbAlias": "mission_control",
                "validationCriteria": {
                    "expectedRows": 15
                },
                "mapDetails": {
                    "showOnMap": false
                },
                "nextMissionId": 2
            },
            {
                "id": 2,
                "title": "Cosmic Cartography: Calibration Scan (SELECT, FROM, WHERE, LIMIT)",
                "description": "Boss: Analyst #6023, your indoctrination into basic human data protocols is complete. Our long-range sensor arrays observing the Sol system require urgent calibration due to anomalous gravimetric distortions. Your task is to assist by performing a targeted data scan of the `deep_space_catalog`. We must sift through this preliminary cosmic data to refine our approach vector to Earth.<br><br><strong>Part 1: Mastering SQL Filters and Data Culling</strong><br>This mission introduces crucial commands for precise data extraction:<ul><li>The <code>WHERE</code> clause is paramount for filtering extraneous data based on specific parameters.</li><li>The <code>LIMIT</code> clause will allow you to control the volume of retrieved data, essential for bandwidth management.</li></ul><br><strong>Your Directives:</strong><br>1. Access the DB REGISTRY and activate the <code>deep_space_catalog</code> archive.<br>2. Execute a query to extract specific columns from the <code>DeepSpaceObjects</code> table:<br><code>SELECT object_name, object_type, distance_ly<br>FROM DeepSpaceObjects<br>WHERE star_system = 'Xylos Sector'<br>LIMIT 5;</code><br><br>The Boss elaborates: This query is designed to:<ul><li>Isolate only the <code>object_name</code>, <code>object_type</code>, and <code>distance_ly</code> for brevity.</li><li>Filter results to display only objects logged within the 'Xylos Sector'.</li><li>Restrict the output to the first 5 records to ensure rapid calibration.</li></ul><br><strong>Intelligence Requirement:</strong> From your 5-entry scan of the Xylos Sector, what is the <code>object_name</code> of the <strong>third</strong> celestial body listed in your results? This specific datum is required to confirm sensor accuracy. Report this name via the answer field.",
                "hint": "Mount <code>deep_space_catalog</code>. Run the query: <code>SELECT object_name, object_type, distance_ly FROM DeepSpaceObjects WHERE star_system = 'Xylos Sector' LIMIT 5;</code> Then identify the third object name from the results and type it in.",
                "solution": "SELECT object_name, object_type, distance_ly FROM DeepSpaceObjects WHERE star_system = 'Xylos Sector' LIMIT 5;",
                "difficulty": 1,
                "points": 50,
                "timeLimit": 300,
                "timerEnabled": false,
                "successMessage": "Calibration successful, Agent! Identifying 'Xylos Gamma' confirms sensor accuracy. This targeted data retrieval is key. Every accurate query refines our path to Earth.",
                "dbAlias": "deep_space_catalog",
                "validationCriteria": {
                    "requiredDatabase": "deep_space_catalog",
                    "answerToQuestion": "Xylos Gamma"
                },
                "mapDetails": {
                    "showOnMap": false
                },
                "nextMissionId": 3
            },
            {
                "id": 3,
                "title": "Signal Triangulation: Potential Havens? (AND, OR)",
                "description": "Boss: Excellent calibration, Analyst #6023. With our sensors sharpened, we are detecting faint anomalous signals from various sectors. We suspect these could indicate resource-rich locations or, critically, potential interim safe havens for our long-range recon units. Your mission is to analyze the <code>deep_space_catalog</code> for objects fitting specific criteria defined by our xenolinguistics and astrometrics team. They theorize that promising locations will be <code>'Planet'</code> type objects that are either flagged as <code>is_habitable_candidate = TRUE</code> <strong>OR</strong> exhibit a <code>spectral_signature</code> of <code>'Water'</code>.<br><br><strong>Part 1: Implementing Complex Logic Filters</strong><br>You will now employ more sophisticated filtering using logical operators:<ul><li><code>AND</code> requires all specified conditions to be met for a record to be included.</li><li><code>OR</code> requires at least one of the specified conditions to be met.</li><li>Parentheses <code>()</code> are used to group conditions, ensuring logical operations are processed in the desired order, much like mathematical expressions.</li></ul><br><strong>Part 2: Utilizing the COUNT Function</strong><br>The <code>COUNT()</code> function is a standard human data tool for enumerating records that match your query. Combined with <code>DISTINCT</code>, it ensures you are counting unique entities, preventing redundant data skew.<br><br><strong>Your Directives:</strong><br>1. Ensure the <code>deep_space_catalog</code> remains your active data archive.<br>2. Construct and execute a query to count distinct objects aligning with our established criteria:<br><code>SELECT COUNT(DISTINCT object_name)<br>FROM DeepSpaceObjects<br>WHERE object_type = 'Planet'<br>AND (is_habitable_candidate = TRUE<br>OR spectral_signature = 'Water');</code><br><br>The Boss clarifies: This query sequence will:<ul><li>Enumerate unique planetary object names.</li><li>First, narrow the search to only 'Planet' type objects.</li><li>Then, apply a compound filter: The planet must be a habitable candidate OR possess a water-based spectral signature.</li></ul><br><strong>Intelligence Requirement:</strong> Based on these parameters (<code>object_type = 'Planet'</code> AND (<code>is_habitable_candidate = TRUE</code> OR <code>spectral_signature = 'Water'</code>)), what is the total count of distinct planetary objects identified across the entire <code>DeepSpaceObjects</code> archive? Input the numerical count.",
                "hint": "Use a query like: <code>SELECT COUNT(DISTINCT object_name) FROM DeepSpaceObjects WHERE object_type = 'Planet' AND (is_habitable_candidate = TRUE OR spectral_signature = 'Water');</code>. Type the resulting number.",
                "solution": "SELECT COUNT(DISTINCT object_name) FROM DeepSpaceObjects WHERE object_type = 'Planet' AND (is_habitable_candidate = TRUE OR spectral_signature = 'Water');",
                "difficulty": 2,
                "points": 75,
                "timeLimit": 300,
                "timerEnabled": false,
                "successMessage": "You found 8 candidate planets. Interesting... Further analysis of their detailed telemetry reveals high M-class radiation on several, and others are primarily methane-ice. Not ideal first stops. We need a more direct approach: Let's find the *closest confirmed* habitable candidate. Time to prioritize by distance!",
                "dbAlias": "deep_space_catalog",
                "validationCriteria": {
                    "requiredDatabase": "deep_space_catalog",
                    "answerToQuestion": "8"
                },
                "mapDetails": {
                    "showOnMap": false
                },
                "nextMissionId": 4
            },
            {
                "id": 4,
                "title": "Astro-Logistics: Nearest Habitable Hope (ORDER BY)",
                "description": "Boss: Analyst #6023, your previous scan provided a useful, albeit broad, list of candidates. We need to refine this further. Command strategy dictates prioritizing targets based on proximity to minimize temporal distortion and resource expenditure. Your new directive: from the <code>DeepSpaceObjects</code> table, identify all <code>'Planet'</code> type objects that are confirmed as <code>is_habitable_candidate = TRUE</code> and present them in order of distance.<br><br><strong>Part 1: Understanding Data Sorting with ORDER BY</strong><br>For this, you will employ the <code>ORDER BY</code> clause, a fundamental data arrangement tool:<ul><li><code>ORDER BY column_name</code> - This sorts your retrieved data based on the values in the specified column.</li><li><code>ASC</code> - Signifies Ascending order (e.g., smallest to largest, A to Z). This is the default if no order is specified.</li><li><code>DESC</code> - Signifies Descending order (e.g., largest to smallest, Z to A).</li></ul><br><strong>Your Directives:</strong><br>1. Confirm the <code>deep_space_catalog</code> is still your active data source.<br>2. Construct a query to list all confirmed habitable planets, sorted by their proximity to our current coordinates:<br><code>SELECT object_name, star_system, distance_ly<br>FROM DeepSpaceObjects<br>WHERE object_type = 'Planet'<br>AND is_habitable_candidate = TRUE<br>ORDER BY distance_ly ASC;</code><br><br>The Boss elaborates: This query will execute the following:<ul><li>Retrieve the object's name, its parent star system, and its distance in light years.</li><li>Filter the dataset to include only objects classified as planets.</li><li>Further refine the filter to only include those planets confirmed as habitable candidates.</li><li>Crucially, sort the results by the <code>distance_ly</code> field in ascending order, ensuring the closest planets appear first.</li></ul><br><strong>Intelligence Requirement:</strong> After executing this query and <strong>ORDERING</strong> the results by <code>distance_ly</code> in <strong>ascending</strong> order, what is the <code>object_name</code> of the <em>closest</em> such habitable planet? This information is vital for our next navigational jump.",
                "hint": "Use: <code>SELECT object_name FROM DeepSpaceObjects WHERE object_type = 'Planet' AND is_habitable_candidate = TRUE ORDER BY distance_ly ASC LIMIT 1;</code> The name of this single planet is your answer.",
                "solution": "SELECT object_name, star_system, distance_ly FROM DeepSpaceObjects WHERE object_type = 'Planet' AND is_habitable_candidate = TRUE ORDER BY distance_ly ASC;",
                "difficulty": 2,
                "points": 100,
                "timeLimit": 300,
                "timerEnabled": false,
                "successMessage": "Excellent prioritization! 'Earth' is indeed the closest confirmed habitable candidate on our list at only 0.0000158 light years away. This is a significant discovery! Our journey is taking us closer to our target system, Sol.",
                "dbAlias": "deep_space_catalog",
                "validationCriteria": {
                    "requiredDatabase": "deep_space_catalog",
                    "answerToQuestion": "Earth"
                },
                "mapDetails": {
                    "showOnMap": false
                },
                "nextMissionId": 5
            },
            {
                "id": 5,
                "title": "Systemic Analysis: Habitable Hotspots (GROUP BY)",
                "description": "Boss: Analyst #6023, pinpointing 'Earth' as the closest candidate is a significant breakthrough. However, effective long-term strategy requires understanding regional galactic demographics. For efficient allocation of future deep-survey resources, we need a summary of 'habitable hotspots' – star systems that host multiple promising worlds. Your task is to analyze the <code>DeepSpaceObjects</code> table, focusing on objects where <code>object_type = 'Planet'</code> AND <code>is_habitable_candidate = TRUE</code>.<br><br><strong>Part 1: Understanding Data Aggregation and Grouping</strong><br>This mission introduces data grouping and aggregation functionalities:<ul><li><code>GROUP BY</code> - This powerful clause groups rows that share identical values in specified columns into summary rows.</li><li><code>COUNT(*)</code> - When used with <code>GROUP BY</code>, this counts the number of rows (in this case, planets) within each group (star system).</li><li><code>AS</code> - This allows you to assign a custom name (alias) to a result column, enhancing readability (e.g., renaming <code>COUNT(*)</code> to <code>habitable_planet_count</code>).</li></ul><br><strong>Your Directives:</strong><br>1. Ensure the <code>deep_space_catalog</code> remains mounted and active.<br>2. Formulate a query that groups these habitable candidate planets by their respective star systems and counts them:<br><code>SELECT star_system, COUNT(*) AS habitable_planet_count<br>FROM DeepSpaceObjects<br>WHERE object_type = 'Planet'<br>AND is_habitable_candidate = TRUE<br>GROUP BY star_system<br>ORDER BY habitable_planet_count DESC;</code><br><br>The Boss decodes the query: This command sequence will:<ul><li>Group the previously filtered habitable planets based on their <code>star_system</code>.</li><li>Calculate the number of habitable planets within each unique star system.</li><li>Assign the alias 'habitable_planet_count' to this calculated number for clarity.</li><li>Sort these star systems based on their count of habitable planets, in descending order, to highlight the most populated systems first.</li></ul><br><strong>Intelligence Requirement:</strong> By <strong>GROUPING</strong> these potential Earth-like planets by their <code>star_system</code> and enumerating them, which <code>star_system</code> is identified as hosting the highest number of these habitable candidate planets? Report the name of this star system. This will inform our secondary survey priorities.",
                "hint": "Use: <code>SELECT star_system, COUNT(*) AS habitable_planet_count FROM DeepSpaceObjects WHERE object_type = 'Planet' AND is_habitable_candidate = TRUE GROUP BY star_system ORDER BY habitable_planet_count DESC LIMIT 1;</code> The star system name is your answer.",
                "solution": "SELECT star_system, COUNT(*) AS habitable_planet_count FROM DeepSpaceObjects WHERE object_type = 'Planet' AND is_habitable_candidate = TRUE GROUP BY star_system ORDER BY habitable_planet_count DESC;",
                "difficulty": 3,
                "points": 125,
                "timeLimit": 360,
                "timerEnabled": false,
                "successMessage": "Precisely! The 'TRAPPIST-1' system shows the most habitable candidates with 4 planets, making it an excellent study target. However, our previous mission identified that Earth in the Sol system is the closest habitable planet, which makes it our priority target for immediate exploration.",
                "dbAlias": "deep_space_catalog",
                "validationCriteria": {
                    "requiredDatabase": "deep_space_catalog",
                    "answerToQuestion": "TRAPPIST-1"
                },
                "mapDetails": {
                    "showOnMap": false
                },
                "nextMissionId": 6
            },
            {
                "id": 6,
                "title": "The Sol Prospect: Finding Home (All Commands)",
                "description": "Boss: Analyst #6023, this is the critical juncture. All prior analyses and intelligence reports confirm our primary target designation: 'Earth', located within the 'Sol' star system. Previous operations utilized broad survey databases. Now, you must access a highly detailed, localized archive: <code>solar_system_archive</code>. You are to mount this database immediately.<br><br><strong>Part 1: Synergizing Your SQL Expertise</strong><br>This conclusive mission in our galactic approach phase will require you to synthesize all SQL techniques acquired thus far:<ul><li>Mounting and accessing a new, specialized data archive.</li><li>Applying multiple precise filter conditions using <code>AND</code>.</li><li>Arranging results for priority using <code>ORDER BY</code>.</li><li>Isolating the single most relevant record with <code>LIMIT</code>.</li></ul><br><strong>Your Directives:</strong><br>1. Access the DB REGISTRY and urgently mount the <code>solar_system_archive</code> database.<br>2. Construct and execute a query to pinpoint Earth based on its known astrometric and biological markers:<br><code>SELECT planet_name, orbital_position, atmosphere_composition<br>FROM SolSystemPlanets<br>WHERE type = 'Rocky'<br>AND orbital_position = 3<br>AND biosignature_detected = TRUE<br>ORDER BY magnetic_field_strength_tesla DESC<br>LIMIT 1;</code><br><br>The Boss provides critical parameters for identification from the archive:<ul><li>It queries for planets of a 'Rocky' composition.</li><li>It specifies the target must be in the third orbital position from its star.</li><li>A confirmed biosignature detection (<code>biosignature_detected = TRUE</code>) is mandatory.</li><li>In the unlikely event of multiple anomalous matches, the query prioritizes the body with the highest <code>magnetic_field_strength_tesla</code> (descending order) and returns only the top record.</li></ul>Earth is known to conform to these characteristics: <code>type = 'Rocky'</code>, <code>orbital_position = 3</code>, and possesses <code>biosignature_detected = TRUE</code>.<br><br><strong>Intelligence Requirement:</strong> Utilizing these exact criteria in your query on the <code>SolSystemPlanets</code> table, and retrieving its <code>planet_name</code>, what is the confirmed designation of our target planet? Provide this name. Its confirmation is paramount.",
                "hint": "Mount `solar_system_archive`. Query: <code>SELECT planet_name FROM SolSystemPlanets WHERE type = 'Rocky' AND orbital_position = 3 AND biosignature_detected = TRUE ORDER BY magnetic_field_strength_tesla DESC LIMIT 1;</code> The answer is the name.",
                "solution": "SELECT planet_name, orbital_position, atmosphere_composition FROM SolSystemPlanets WHERE type = 'Rocky' AND orbital_position = 3 AND biosignature_detected = TRUE ORDER BY magnetic_field_strength_tesla DESC LIMIT 1;",
                "difficulty": 3,
                "points": 150,
                "timeLimit": 420,
                "timerEnabled": false,
                "successMessage": "TARGET ACQUIRED! 'Earth' confirmed! Your SQL mastery has guided us across the void. Data relayed. Stand by to engage the planetary observation interface on the interactive map. Mission success!",
                "dbAlias": "solar_system_archive",
                "validationCriteria": {
                    "requiredDatabase": "solar_system_archive",
                    "answerToQuestion": "Earth"
                },
                "mapDetails": {
                    "showOnMap": false
                },
                "nextMissionId": 7
            },
            {
                "id": 7,
                "title": "Tutorial: Interactive Map",
                "description": "Boss: Analyst #6023, your successful identification of 'Earth' transitions us to the planetary approach phase. Excellent work. Now, we must familiarize you with Earth's own geographical data representation systems. You'll learn to use their 'interactive map' feature, which integrates SQL queries with visual geographic displays.<br><br><strong>Part 1: Understanding Interactive Database Visualization</strong><br>Their SQL systems are not limited to textual data; they can represent geographical information visually. In this orientation, you will learn to:<ul><li>Mount a specialized geographic database.</li><li>Utilize SQL to query location-based data.</li><li>Observe how these query results are rendered on an interactive map interface.</li></ul><br><strong>Your Directives:</strong><br>1. Access the <strong>DB REGISTRY</strong> system interface.<br>2. Locate the <strong>maps</strong> database and engage its <strong>MOUNT</strong> protocol.<br>3. Close the DB Registry panel.<br>4. Via the SQL console, execute the following query:<br><code>SELECT * FROM countries WHERE continent = 'North America';</code><br><br>The Boss explains the output:<ul><li>This query is designed to retrieve all data pertaining to countries located on the continent they designate 'North America'.</li><li>The raw data will populate the results area as before.</li><li>Crucially, the system's map integration protocols will automatically highlight these designated countries on its display.</li><li>You can then engage the MAP interface button for a full interactive cartographic representation.</li></ul>This skill is fundamental for identifying and targeting specific surface locations in subsequent missions.",
                "hint": "First mount the 'maps' database, then run: <code>SELECT * FROM countries WHERE continent = 'North America';</code> to view North American countries. You can then open the map to see them highlighted.",
                "solution": "SELECT * FROM countries WHERE continent = 'North America';",
                "difficulty": 1,
                "points": 50,
                "timeLimit": 300,
                "timerEnabled": false,
                "successMessage": "Perfect! You've successfully queried geographical data and seen it visualized on the map. This skill will be essential for locating mission sites around the world. IMPORTANT: Your next missions will be accessed through the MAP interface. Open the map, locate the mission markers, and click on them to begin those missions.",
                "dbAlias": "maps",
                "validationCriteria": {
                    "databaseMounted": true,
                    "requiredDatabase": "maps",
                    "keywords": [
                        "SELECT",
                        "FROM",
                        "countries",
                        "continent",
                        "North America"
                    ]
                },
                "mapDetails": {
                    "showOnMap": false
                },
                "nextMissionId": 8
            },
            {
                "id": 8,
                "title": "Global Geography Analysis",
                "description": "Boss: Analyst #6023, you've demonstrated aptitude with Earth's basic mapping systems. Now, we proceed to pinpoint our initial surface-level analysis zone. Your first primary field mission is slated for a high-density urban agglomeration known as 'New York City', within the geopolitical entity 'United States'. You will use SQL and the interactive map to isolate this location.<br><br><strong>Part 1: Refining Location Targeting</strong><br>This task requires precision in querying specific geographic entities:<ul><li>Employ SQL to interrogate the location data archives.</li><li>Apply filters to isolate data relevant to our target mission destination.</li><li>Utilize the interactive map for visual confirmation of the highlighted target zones.</li></ul><br><strong>Your Directives:</strong><br>1. Confirm the <code>maps</code> database remains the active data source.<br>2. First, execute a query to gather information concerning the 'United States':<br><code>SELECT * FROM countries WHERE country = 'United States';</code><br><br>3. Next, refine your query to focus on urban centers within that entity:<br><code>SELECT * FROM cities WHERE country = 'United States';</code><br><br>4. Subsequent to reviewing the textual data, activate the <strong>MAP</strong> interface at the top of your console to observe the highlighted locations. This visual confirmation is standard procedure.<br><br>These queries will furnish data on the 'United States' and its principal urban centers, including 'New York City,' your designated site for the upcoming mission. Familiarize yourself with its context.",
                "hint": "Run <code>SELECT * FROM cities WHERE country = 'United States';</code> to see US cities including New York. Then click the MAP button to view the full interactive map.",
                "solution": "SELECT * FROM cities WHERE country = 'United States';",
                "difficulty": 2,
                "points": 75,
                "timeLimit": 300,
                "timerEnabled": false,
                "successMessage": "Excellent! You've successfully located New York City, our first mission location. You've mastered using SQL queries to find geographic data and using the interactive map for visualization. Your next mission awaits in New York City!",
                "dbAlias": "maps",
                "validationCriteria": {
                    "databaseMounted": true,
                    "requiredDatabase": "maps",
                    "keywords": [
                        "SELECT",
                        "FROM",
                        "cities",
                        "country",
                        "United States"
                    ]
                },
                "mapDetails": {
                    "showOnMap": true,
                    "country": "United States",
                    "location": [
                        -74.0060,
                        40.7128
                    ],
                    "description": "Locate New York City, your first mission destination."
                },
                "nextMissionId": 9
            },
            {
                "id": 9,
                "title": "Mission: First Contact (New York)",
                "description": "Boss: Analyst #6023, prepare for 'First Contact Protocol Omega-7'. The Galactic Council requires urgent baseline demographic data on Earth's major population centers. Our initial focus is the previously identified megacity: New York. Your SQL proficiency is now critical for direct planetary data extraction.<br><br><strong>Part 1: Applying SQL for Terrestrial Intelligence</strong><br>This operation involves leveraging your acquired SQL skills to interrogate Earth-specific data repositories:<ul><li>You will mount a specialized database containing detailed terrestrial demographic data.</li><li>Employ the WHERE clause to isolate data pertinent to 'New York City'.</li><li>Extract specific population metrics for immediate relay to the Council.</li></ul><br><strong>Your Directives:</strong><br>1. Access the <strong>DB REGISTRY</strong> and mount the <code>geo_data_earth</code> archive. This contains detailed planetary metrics.<br>2. Formulate and execute a query to extract information on New York City:<br><code>SELECT population, country<br>FROM EarthCities<br>WHERE city_name = 'New York';</code><br><br>The Boss elaborates on the query's function:<ul><li>It selects only the <code>population</code> count and the parent <code>country</code> identifier.</li><li>It applies a filter to retrieve data exclusively for the urban zone designated 'New York'.</li><li>The output will be the specific demographic information required by the Galactic Council for their planetary assessment models.</li></ul><br><strong>Expected Intelligence Yield:</strong><br>The query must return a single data row containing New York's population figures and its associated country designator ('United States'). Precision is paramount.",
                "hint": "Mount `geo_data_earth`. Use `SELECT population, country FROM EarthCities WHERE city_name = 'New York';`",
                "solution": "SELECT population, country FROM EarthCities WHERE city_name = 'New York';",
                "difficulty": 1,
                "points": 100,
                "timeLimit": 300,
                "timerEnabled": false,
                "successMessage": "Excellent work, SQL Knight! You've successfully retrieved the data for New York. This is vital for the Galactic Council.",
                "dbAlias": "geo_data_earth",
                "validationCriteria": {
                    "expectedRows": 1,
                    "mustContainColumns": ["population", "country"],
                    "queryStructureChecks": [
                        {"checkType": "filter", "column": "city_name", "expectedValue": "New York"}
                    ],
                    "keywords": ["SELECT", "FROM", "EarthCities", "WHERE"]
                },
                "mapDetails": {
                    "showOnMap": true,
                    "country": "United States",
                    "location": [
                        -74.0060,
                        40.7128
                    ],
                    "description": "First Contact mission in New York. Objective: Query city data."
                },
                "nextMissionId": 10
            },
            {
                "id": 10,
                "title": "Mission: Resource Discovery (London)",
                "description": "Boss: Analyst #6023, the Galactic Trading Federation has an interest in Earth. They require intelligence on key terrestrial resources located near major European commerce hubs. Your next assignment is to focus on the city of London, within the 'United Kingdom' geo-political zone, and identify valuable local resources.<br><br><strong>Part 1: Advanced Filtering and Sorting of Earth Resources</strong><br>This mission will require you to combine multiple SQL techniques to analyze resource data effectively:<ul><li>Employ multiple filter conditions simultaneously using the AND operator.</li><li>Utilize comparison operators (e.g., >) to assess quantitative values.</li><li>Sort your results by value in descending order to highlight the most significant findings.</li></ul><br><strong>Your Directives:</strong><br>1. Ensure the <code>geo_data_earth</code> database remains active and accessible.<br>2. Construct a query to identify high-value resources within the United Kingdom:<br><code>SELECT resource_name, market_value<br>FROM EarthResources<br>WHERE country_origin = 'United Kingdom'<br>AND market_value > 5000<br>ORDER BY market_value DESC;</code><br><br>The Boss details the query logic:<ul><li>It selects resource designations and their corresponding market values.</li><li>It applies two critical filter conditions:</li><ul><li>Resources must originate from the 'United Kingdom'.</li><li>Their assessed <code>market_value</code> must exceed 5000 Federation credits.</li></ul><li>The results are then sorted with the highest value resources listed first, for Federation prioritization.</li></ul><br><strong>Intelligence Requirement:</strong><br>Upon execution of this query, what is the <code>resource_name</code> of the most valuable resource (possessing the highest <code>market_value</code>) in the United Kingdom according to their data? Provide the exact resource name. The Federation awaits this information for their trade route planning.",
                "hint": "Use `SELECT resource_name, market_value FROM EarthResources WHERE country_origin = 'United Kingdom' AND market_value > 5000 ORDER BY market_value DESC;` and note the name of the resource with the highest market_value.",
                "solution": "SELECT resource_name, market_value FROM EarthResources WHERE country_origin = 'United Kingdom' AND market_value > 5000 ORDER BY market_value DESC;",
                "difficulty": 2,
                "points": 150,
                "timeLimit": 300,
                "timerEnabled": false,
                "successMessage": "Outstanding work! The Galactic Trading Federation can now prioritize the most valuable resources for their European commercial routes.",
                "dbAlias": "geo_data_earth",
                "validationCriteria": {
                    "requiredDatabase": "geo_data_earth",
                    "answerToQuestion": "Scottish Rare Earth Elements"
                },
                "mapDetails": {
                    "showOnMap": true,
                    "country": "United Kingdom",
                    "location": [
                        -0.1278,
                        51.5074
                    ],
                    "description": "Resource Discovery mission in London. Objective: Query valuable UK resources."
                },
                "nextMissionId": 11
            },
            {
                "id": 11,
                "title": "Mission: Cultural Heritage Scan (Tokyo)",
                "description": "Boss: Analyst #6023, our cultural archivists, the Interstellar Preservation Society, are compiling a catalog of Earth's sites of significant cultural importance. Their current focus is Tokyo, Japan. They require a chronologically ordered list of noteworthy cultural sites.<br><br><strong>Part 1: Complex Filtering with AND/OR Logic Combinations</strong><br>This assignment involves sophisticated data filtering and sorting techniques:<ul><li>You will need to combine AND and OR conditions, using parentheses for correct logical grouping.</li><li>Results must be sorted chronologically (oldest first) using ASC order.</li><li>Your objective is to extract data pertaining to cultural heritage.</li></ul><br><strong>Your Directives:</strong><br>1. Maintain access to the <code>geo_data_earth</code> database.<br>2. Formulate a query to identify significant cultural locations in Tokyo:<br><code>SELECT site_name, year_established<br>FROM EarthSites<br>WHERE city = 'Tokyo'<br>AND (type = 'Cultural' OR importance_level >= 8)<br>ORDER BY year_established ASC;</code><br><br>The Boss deciphers the query for optimal execution:<ul><li>It retrieves site names and their respective years of establishment.</li><li>The primary filter restricts data to sites located within 'Tokyo'.</li><li>A secondary, compound condition is applied: the site must EITHER be classified as 'Cultural' OR possess an 'importance_level' of 8 or higher on their scale.</li><li>Finally, the results are ordered by <code>year_established</code> in ascending order, presenting the oldest sites first for the Society's cataloging protocol.</li></ul><br><strong>Intelligence Requirement:</strong><br>What is the <code>site_name</code> of the oldest site in Tokyo that meets the criteria of being 'Cultural' or having an <code>importance_level >= 8</code>? Report the exact site name from your query results. The Preservation Society is keen to document this earliest significant location.",
                "hint": "Use `SELECT site_name, year_established FROM EarthSites WHERE city = 'Tokyo' AND (type = 'Cultural' OR importance_level >= 8) ORDER BY year_established ASC;` and look at the first result (oldest site).",
                "solution": "SELECT site_name, year_established FROM EarthSites WHERE city = 'Tokyo' AND (type = 'Cultural' OR importance_level >= 8) ORDER BY year_established ASC;",
                "difficulty": 2,
                "points": 200,
                "timeLimit": 300,
                "timerEnabled": false,
                "successMessage": "Well done! The Interstellar Preservation Society can now catalog Tokyo's key heritage sites effectively, starting with the oldest site: Sensō-ji Temple from 645 CE.",
                "dbAlias": "geo_data_earth",
                "validationCriteria": {
                    "requiredDatabase": "geo_data_earth",
                    "answerToQuestion": "Sensō-ji Temple"
                },
                "mapDetails": {
                    "showOnMap": true,
                    "country": "Japan",
                    "location": [
                        139.6917,
                        35.6895
                    ],
                    "description": "Cultural Heritage Scan in Tokyo. Objective: Query significant sites."
                },
                "nextMissionId": 12
            },
            {
                "id": 12,
                "title": "Paris With Love: Sustainable Tech Analysis",
                "description": "Boss: Analyst #6023, our operatives have flagged a human research initiative in Paris, France, dedicated to studying historical sustainability techniques. This aligns with our observation directives. You are to access a new archive, the <code>GlobalTechArchive</code> (aliased as <code>global_tech</code> in their systems), to provide this team with relevant data.<br><br><strong>Part 1: Mastering Combined SQL Operations</strong><br>This mission will test your ability to synthesize multiple SQL techniques into a single, efficient query:<ul><li>Applying multiple filter conditions using diverse logical operators.</li><li>Sorting data effectively with ORDER BY.</li><li>Utilizing LIMIT to restrict results to the most pertinent information.</li></ul><br><strong>Your Directives:</strong><br>1. Access the DB REGISTRY and ensure you mount the <code>global_tech</code> database. This archive contains data on historical and contemporary technological practices.<br>2. Construct a query to identify notable sustainable practices originating from 'France':<br><code>SELECT practice_name, efficiency_rating<br>FROM SustainabilityPractices<br>WHERE country_of_origin = 'France'<br>AND (category = 'Urban' OR category = 'Agricultural')<br>ORDER BY efficiency_rating DESC<br>LIMIT 3;</code><br><br>The Boss provides clarification on this complex query:<ul><li>It selects the name of the practice and its designated efficiency rating.</li><li>It filters for practices specifically originating from 'France'.</li><li>It further refines this by including practices that fall into EITHER the 'Urban' OR 'Agricultural' categories.</li><li>The results are then sorted by the <code>efficiency_rating</code> in descending order (highest to lowest).</li><li>Finally, the query is restricted to return only the top 3 most efficient practices, providing focused data for the Parisian researchers.</li></ul><br><strong>Expected Intelligence Yield:</strong><br>Your query should yield the three most efficient sustainable practices from France, focusing on urban and agricultural sectors. This data is intended to aid the Parisian team in adapting historical methods for contemporary challenges.",
                "hint": "Access the DB REGISTRY and mount `global_tech`. Use `SELECT practice_name, efficiency_rating FROM SustainabilityPractices WHERE country_of_origin = 'France' AND (category = 'Urban' OR category = 'Agricultural') ORDER BY efficiency_rating DESC LIMIT 3;`",
                "solution": "SELECT practice_name, efficiency_rating FROM SustainabilityPractices WHERE country_of_origin = 'France' AND (category = 'Urban' OR category = 'Agricultural') ORDER BY efficiency_rating DESC LIMIT 3;",
                "difficulty": 3,
                "points": 200,
                "timeLimit": 300,
                "timerEnabled": false,
                "successMessage": "Magnifique! You've unlocked ancient sustainability knowledge that will help modern Paris. Your combined use of WHERE, OR, ORDER BY, and LIMIT was flawless!",
                "dbAlias": "global_tech",
                "validationCriteria": {
                    "keywords": ["SELECT", "FROM", "SustainabilityPractices", "WHERE", "AND", "OR", "ORDER BY", "DESC", "LIMIT"],
                    "queryStructureChecks": [
                        {"checkType": "filter", "column": "country_of_origin", "expectedValue": "France"},
                        {"checkType": "limit", "expectedValue": 3}
                    ],
                    "queryLogicChecks": [
                         {"clause": "WHERE", "mustContainLogicCombination": {"AND": ["country_of_origin = 'France'", {"OR": ["category = 'Urban'", "category = 'Agricultural'"]}]}}
                    ],
                    "ordered": true,
                    "orderColumn": "efficiency_rating",
                    "orderDirection": "desc",
                    "mustContainColumns": ["practice_name", "efficiency_rating"],
                    "expectedRows": 3
                },
                "mapDetails": {
                    "showOnMap": true,
                    "country": "France",
                    "location": [
                        2.3522,
                        48.8566
                    ],
                    "description": "Active mission in Paris: Query sustainable tech."
                },
                "nextMissionId": 13
            },
            {
                "id": 13,
                "title": "Mission: Sydney Bio-Diversity Report (GROUP BY)",
                "description": "Boss: Analyst #6023, we've received a request from human environmental scientists in Sydney, Australia. They require a summary of regional wildlife sightings, with a particular focus on species under threat. You'll need to access and analyze the <code>RegionalWildlifeDB</code> (aliased as <code>aus_wildlife</code>) for this task.<br><br><strong>Part 1: Implementing Advanced Data Aggregation and Filtering</strong><br>This assignment will further develop your skills in advanced data aggregation:<ul><li>Utilizing the COUNT function in conjunction with the DISTINCT keyword to ensure unique species counts.</li><li>Filtering data based on complex OR conditions for conservation statuses.</li><li>Combining GROUP BY with ORDER BY for structured and prioritized reporting.</li><li>Employing aliases for result columns to enhance clarity for the human scientists.</li></ul><br><strong>Your Directives:</strong><br>1. Proceed to the DB REGISTRY and mount the <code>aus_wildlife</code> database. This archive is specific to Australian faunal sightings.<br>2. Construct and execute a query to analyze endangered species distribution across Australian states and provinces:<br><code>SELECT state_province, COUNT(DISTINCT species_name) AS endangered_species_count<br>FROM SightingsAustralia<br>WHERE conservation_status = 'Endangered'<br>OR conservation_status = 'Critically Endangered'<br>GROUP BY state_province<br>ORDER BY endangered_species_count DESC;</code><br><br>The Boss provides critical insights into the query's mechanics:<ul><li>It groups wildlife sighting records by their respective <code>state_province</code>.</li><li>It counts only unique <code>species_name</code> entries within each group, thus avoiding over-counting from multiple sightings of the same species.</li><li>The query filters these sightings to include only species designated as 'Endangered' OR 'Critically Endangered'.</li><li>The resultant count column is aliased as 'endangered_species_count' for direct interpretability.</li><li>Finally, the output is sorted to list regions with the highest number of distinct endangered species first, aiding the scientists in prioritizing conservation efforts.</li></ul><br><strong>Expected Intelligence Yield:</strong><br>This query should generate a clear biodiversity report indicating which Australian states or provinces exhibit the highest concentrations of distinct endangered species. This intelligence is crucial for the Sydney team's conservation strategies.",
                "hint": "Access the DB REGISTRY and mount `aus_wildlife`. Use `SELECT state_province, COUNT(DISTINCT species_name) AS endangered_species_count FROM SightingsAustralia WHERE conservation_status = 'Endangered' OR conservation_status = 'Critically Endangered' GROUP BY state_province ORDER BY endangered_species_count DESC;`",
                "solution": "SELECT state_province, COUNT(DISTINCT species_name) AS endangered_species_count FROM SightingsAustralia WHERE conservation_status = 'Endangered' OR conservation_status = 'Critically Endangered' GROUP BY state_province ORDER BY endangered_species_count DESC;",
                "difficulty": 3,
                "points": 250,
                "timeLimit": 420,
                "timerEnabled": false,
                "successMessage": "Excellent analysis! The scientists now have a clear report on endangered species distribution in Australia thanks to your GROUP BY and aggregate skills.",
                "dbAlias": "aus_wildlife",
                "validationCriteria": {
                    "keywords": ["SELECT", "COUNT", "DISTINCT", "FROM", "SightingsAustralia", "WHERE", "OR", "GROUP BY", "ORDER BY", "DESC"],
                    "queryLogicChecks": [
                        {"clause": "WHERE", "mustContainLogicCombination": {"OR": ["conservation_status = 'Endangered'", "conservation_status = 'Critically Endangered'"]}}
                    ],
                    "aggregation": true,
                    "groupBy": ["state_province"],
                    "aggregateFunction": "COUNT",
                    "aggregateColumn": "species_name",
                    "distinctInAggregation": true,
                    "ordered": true,
                    "orderColumn": "endangered_species_count",
                    "orderDirection": "desc",
                    "mustContainColumns": ["state_province", "endangered_species_count"]
                },
                "mapDetails": {
                    "showOnMap": true,
                    "country": "Australia",
                    "location": [
                        151.2093,
                        -33.8688
                    ],
                    "description": "Sydney Bio-Diversity Report. Objective: Group and count endangered species."
                },
                "nextMissionId": 14
            },
            {
                "id": 14,
                "title": "Mission: Rio Resource Value Analysis (Complex Query)",
                "description": "Boss: Analyst #6023, this is a high-priority directive. The Global Economic Council, currently convened in Rio de Janeiro, Brazil, requires a detailed report on resource export values. You are to access the <code>SouthAmericaEconomyDB</code> (known in their system as <code>sa_econ</code>) for this advanced analytical task.<br><br><strong>Part 1: Mastering Advanced Filtering with the HAVING Clause</strong><br>This mission will push your SQL capabilities to their limits, introducing some of the most sophisticated concepts in human database interrogation:<ul><li>Utilizing the SUM function to calculate aggregate totals (e.g., total export value).</li><li>Employing the HAVING clause to filter results *after* data has been grouped – this is distinct from WHERE.</li><li>Calculating averages using the AVG function within your grouping logic.</li><li>Combining multiple aggregate functions within a single, comprehensive query.</li></ul><br><strong>Your Directives:</strong><br>1. Access the DB REGISTRY and urgently mount the <code>sa_econ</code> database. This archive contains sensitive economic activity data.<br>2. Construct and execute a highly complex query to analyze natural resource exports from the South American continent:<br><code>SELECT country, SUM(export_value) AS total_natural_resource_export_value<br>FROM EconomicActivities<br>WHERE item_type = 'NaturalResource'<br>GROUP BY country<br>HAVING AVG(resource_stability_index) > 0.6<br>ORDER BY total_natural_resource_export_value DESC<br>LIMIT 5;</code><br><br>The Boss breaks down this intricate command:<ul><li>It initially filters for economic activities classified specifically as 'NaturalResource' types.</li><li>These filtered items are then grouped by their <code>country</code> of origin.</li><li>The query calculates the total sum of <code>export_value</code> for these natural resources within each country.</li><li>Crucially, the HAVING clause is applied *after* grouping to filter out countries where the average <code>resource_stability_index</code> is not greater than 0.6. This ensures only economically stable resource exporters are considered.</li><li>The remaining countries are then ordered by their total natural resource export value, highest first.</li><li>Finally, only the top 5 countries from this refined list are returned.</li></ul><br><strong>Distinguishing HAVING from WHERE:</strong><br><ul><li>The WHERE clause filters individual rows *before* any grouping occurs.</li><li>The HAVING clause filters entire groups *after* the GROUP BY clause has processed the data. It often incorporates aggregate functions (AVG, SUM, COUNT) in its conditions, which WHERE cannot do.</li></ul><br><strong>Expected Intelligence Yield:</strong><br>This query will identify the top 5 South American countries with the highest natural resource export values that also demonstrate a significant level of resource stability. This information is of utmost importance for the Global Economic Council's strategic investment planning.",
                "hint": "Access the DB REGISTRY and mount `sa_econ`. A complex one! `SELECT country, SUM(export_value) AS total_natural_resource_export_value FROM EconomicActivities WHERE item_type = 'NaturalResource' GROUP BY country HAVING AVG(resource_stability_index) > 0.6 ORDER BY total_natural_resource_export_value DESC LIMIT 5;`",
                "solution": "SELECT country, SUM(export_value) AS total_natural_resource_export_value FROM EconomicActivities WHERE item_type = 'NaturalResource' GROUP BY country HAVING AVG(resource_stability_index) > 0.6 ORDER BY total_natural_resource_export_value DESC LIMIT 5;",
                "difficulty": 4,
                "points": 300,
                "timeLimit": 480,
                "timerEnabled": false,
                "successMessage": "Outstanding work! The Council now has critical insight into South American natural resource export values. Your full command of SQL, including aggregation, filtering, ordering, and limiting results, is exemplary!",
                "dbAlias": "sa_econ",
                "validationCriteria": {
                    "keywords": ["SELECT", "SUM", "FROM", "EconomicActivities", "WHERE", "GROUP BY", "HAVING", "AVG", "ORDER BY", "DESC", "LIMIT"],
                    "queryStructureChecks": [
                        {"checkType": "filter", "column": "item_type", "expectedValue": "NaturalResource"},
                        {"checkType": "limit", "expectedValue": 5}
                    ],
                    "aggregation": true,
                    "groupBy": ["country"],
                    "aggregateFunction": "SUM",
                    "aggregateColumn": "export_value",
                    "havingClauseCheck": {"aggregateFunction": "AVG", "column": "resource_stability_index", "operator": ">", "value": 0.6},
                    "ordered": true,
                    "orderColumn": "total_natural_resource_export_value",
                    "orderDirection": "desc",
                    "mustContainColumns": ["country", "total_natural_resource_export_value"],
                    "expectedRows": 5
                },
                "mapDetails": {
                    "showOnMap": true,
                    "country": "Brazil",
                    "location": [
                        -43.1729,
                        -22.9068
                    ],
                    "description": "Rio Resource Analysis mission. Objective: Complex aggregation and filtering."
                },
                "nextMissionId": 100
            },
            {
                "id": 100,
                "title": "Data Visualization for Global Goals (SDG Focus)",
                "description": "Boss: Analyst #6023, your prior analyses of regional human economies have been insightful. We are now shifting focus to assist them with broader global development paradigms, specifically their 'Sustainable Development Goals' or SDGs. Data visualization is a primitive yet effective tool they use to translate raw numerical data into comprehensible insights for these goals.<br><br><strong>Part 1: Introduction to Visual Analysis via Charting</strong><br>This phase involves transforming your SQL outputs into visual charts to better understand their global challenges and progress. You will learn to:<ul><li>Execute SQL queries to retrieve key development indicators from their global repositories.</li><li>Utilize their <strong>GRAPH</strong> button functionality to render these results visually.</li><li>Experiment with their rudimentary Bar, Line, and Pie chart formats.</li></ul><br><strong>Your Directives:</strong><br>1. Access the DB REGISTRY and mount the <code>sdg_data_hub</code> database (aliased as <code>sdg_hub</code>). This is a centralized repository for their SDG tracking.<br>2. Query key socio-economic indicators for various global regions for the year 2023:<br><code>SELECT region, indicator_name, value<br>FROM GlobalDevelopmentIndicators<br>WHERE year = 2023 AND indicator_name IN ('LiteracyRate', 'AccessToCleanWater', 'RenewableEnergyUsage');</code><br><br>3. After execution, activate the <strong>GRAPH</strong> button. Observe how different chart types (Bar, Pie) represent this dataset. Note that for time-series data (queries spanning multiple years), a Line chart would typically be their preferred visualization method.<br><br>This mission serves as an introduction to visualizing SDG-related data, a skill crucial for generating impactful reports for their global policy makers.",
                "hint": "Mount `sdg_hub`. Run the query <code>SELECT region, indicator_name, value FROM GlobalDevelopmentIndicators WHERE year = 2023 AND indicator_name IN ('LiteracyRate', 'AccessToCleanWater', 'RenewableEnergyUsage');</code> then click GRAPH. Explore Bar and Pie charts.",
                "solution": "SELECT region, indicator_name, value FROM GlobalDevelopmentIndicators WHERE year = 2023 AND indicator_name IN ('LiteracyRate', 'AccessToCleanWater', 'RenewableEnergyUsage');",
                "difficulty": 1,
                "points": 75,
                "timeLimit": 300,
                "timerEnabled": false,
                "successMessage": "Excellent! You've seen how data visualization with charts makes complex SDG data more accessible. This is crucial for tracking global progress.",
                "dbAlias": "sdg_hub",
                "validationCriteria": {
                    "keywords": ["SELECT", "FROM", "GlobalDevelopmentIndicators", "WHERE", "IN"],
                    "mustContainColumns": ["region", "indicator_name", "value"],
                    "minRows": 3
                },
                "mapDetails": {
                    "showOnMap": true,
                    "country": "Global",
                    "location": [0, 0],
                    "zoomLevel": 1,
                    "description": "Visualizing global SDG indicators."
                },
                "nextMissionId": 101
            },
            {
                "id": 101,
                "title": "Connecting Education & Opportunity (Intro to JOINs for SDGs 4 & 8)",
                "description": "Boss: Analyst #6023, visualizing isolated datasets offers limited insight. To truly aid their SDG efforts, we must combine data from disparate sources to uncover relationships. Your next task is to explore the linkage between human education levels (as per their SDG 4: Quality Education) and subsequent employment outcomes (SDG 8: Decent Work and Economic Growth). This requires a new SQL technique.<br><br><strong>Part 1: Understanding JOIN Operations for Relational Analysis</strong><br>The 'JOIN' operation is how humans merge rows from two or more data tables based on a common, related column. This is fundamental for any relational data analysis. You will:<ul><li>Use the JOIN keyword to connect different tables.</li><li>Specify the precise join conditions using the ON keyword, which defines how the tables are related.</li></ul><br><strong>Your Directives:</strong><br>1. Access the DB REGISTRY and mount the <code>education_employment_link</code> database (aliased as <code>edu_work_data</code>). This contains correlated education and employment statistics.<br>2. Perform a JOIN operation to connect education statistics with employment statistics by country:<br><code>SELECT es.country, es.avg_years_schooling, emps.employment_rate<br>FROM EducationStats AS es<br>JOIN EmploymentStats AS emps ON es.country_code = emps.country_code;</code><br><br>Once the query is executed, activate the <strong>GRAPH</strong> button and select the SCATTER plot visualization. This particular chart type is well-suited for identifying potential correlations between variables like average schooling years and employment rates. Observing these relationships is key to understanding drivers for their SDG 4 and 8.",
                "hint": "Mount `edu_work_data`. Run <code>SELECT es.country, es.avg_years_schooling, emps.employment_rate FROM EducationStats AS es JOIN EmploymentStats AS emps ON es.country_code = emps.country_code;</code> Then view with a Scatter plot.",
                "solution": "SELECT es.country, es.avg_years_schooling, emps.employment_rate FROM EducationStats AS es JOIN EmploymentStats AS emps ON es.country_code = emps.country_code;",
                "difficulty": 2,
                "points": 100,
                "timeLimit": 300,
                "timerEnabled": false,
                "successMessage": "Great! You've used JOIN to connect education and employment data. Scatter plots are useful for spotting potential correlations between such variables.",
                "dbAlias": "edu_work_data",
                "validationCriteria": {
                    "keywords": ["SELECT", "FROM", "EducationStats", "JOIN", "EmploymentStats", "ON"],
                    "mustContainColumns": ["country", "avg_years_schooling", "employment_rate"],
                    "minRows": 5
                },
                "mapDetails": {
                    "showOnMap": false
                },
                "nextMissionId": 102
            },
            {
                "id": 102,
                "title": "Urban Green Spaces & Population (INNER JOIN for SDG 11)",
                "description": "Boss: Analyst #6023, your understanding of JOINs is progressing. We will now focus on 'INNER JOIN'. This specific type of join is critical for analyses related to their SDG 11 (Sustainable Cities and Communities). For example, it allows us to find entities, like cities, for which we have *confirmed, corresponding data* in multiple datasets – such as cities with both recorded population figures and documented green space initiatives.<br><br><strong>Part 1: Achieving Precision with INNER JOIN</strong><br>An INNER JOIN is restrictive: it returns only those rows where there is a matching value in *both* of the joined tables based on the specified join condition.<br><br><strong>Your Directives:</strong><br>1. Ensure the <code>urban_sustainability_data</code> database (aliased as <code>city_sustain_db</code>) is mounted. It contains urban demographic and environmental project data.<br>2. Your task is to identify cities that have data entries in both the city population tables and the green initiative project tables:<br><code>SELECT cp.city_name, cp.population, gi.project_name AS green_initiative_project<br>FROM CityPopulations AS cp<br>INNER JOIN GreenInitiatives AS gi ON cp.city_id = gi.city_id<br>WHERE cp.population > 1000000<br>ORDER BY cp.population DESC;</code><br><br>After execution, try the <strong>GRAPH</strong> button. While this specific query shows direct links, if you were to modify it to GROUP BY city and COUNT projects, a BAR chart would be effective for comparing the number of green initiatives across populous cities. For now, observe the direct linkage produced by the INNER JOIN.<br><br><strong>Intelligence Requirement:</strong> For cities with a population exceeding 1,000,000, how many distinct `green_initiative_project` entries are listed for the urban center designated 'Metro City' in their records? Report this number. This assesses your ability to extract precise, linked data.",
                "hint": "Mount `city_sustain_db`. Query: <code>SELECT cp.city_name, cp.population, gi.project_name AS green_initiative_project FROM CityPopulations AS cp INNER JOIN GreenInitiatives AS gi ON cp.city_id = gi.city_id WHERE cp.population > 1000000 ORDER BY cp.population DESC;</code> Look for 'Metro City'. (Example data needed for a fixed answer, for now, it validates query structure)",
                "solution": "SELECT cp.city_name, cp.population, gi.project_name AS green_initiative_project FROM CityPopulations AS cp INNER JOIN GreenInitiatives AS gi ON cp.city_id = gi.city_id WHERE cp.population > 1000000 ORDER BY cp.population DESC;",
                "difficulty": 2,
                "points": 125,
                "timeLimit": 300,
                "timerEnabled": false,
                "successMessage": "Excellent! INNER JOIN helped you link cities to their specific green initiatives, a key aspect of sustainable urban development (SDG 11).",
                "dbAlias": "city_sustain_db",
                "validationCriteria": {
                    "keywords": ["SELECT", "FROM", "CityPopulations", "INNER JOIN", "GreenInitiatives", "ON", "WHERE"],
                    "mustContainColumns": ["city_name", "population", "green_initiative_project"],
                    "answerToQuestion": "3"
                },
                "mapDetails": {
                    "showOnMap": false
                },
                "nextMissionId": 103
            },
            {
                "id": 103,
                "title": "Educational Resource Availability (LEFT JOIN for SDG 4)",
                "description": "Boss: Analyst #6023, to effectively address SDG 4 (Quality Education), human policymakers need a comprehensive overview of educational resource distribution. This includes identifying where data might be *missing*. For this, the 'LEFT JOIN' is invaluable. It allows us to list all educational institutions, for instance, and then append resource data where it exists, thereby highlighting gaps where such data is not reported.<br><br><strong>Part 1: Ensuring Inclusive Reporting with LEFT JOIN</strong><br>A LEFT JOIN returns all rows from the 'left' table (the first table listed) and the matched rows from the 'right' table. If there's no match for a row from the left table in the right table, the result will still include the row from the left table, but with NULL values for columns from the right table.<br><br><strong>Your Directives:</strong><br>1. Access the DB REGISTRY and mount the <code>education_infra_db</code> database (aliased as <code>edu_data</code>). This archive contains data on educational institutions and their reported digital resources.<br>2. Your objective is to list all schools and, where available, their reported internet access status:<br><code>SELECT s.school_name, s.district, dr.has_internet<br>FROM Schools AS s<br>LEFT JOIN DigitalResourceReports AS dr ON s.school_id = dr.school_id<br>ORDER BY s.district, s.school_name;</code><br><br>Utilize the <strong>GRAPH</strong> button post-query. A Line chart, perhaps constructed by counting schools where `has_internet` is TRUE, FALSE, and where it IS NULL (indicating no report), could effectively illustrate the coverage of digital resource reporting across their school systems.<br><br><strong>Intelligence Requirement:</strong> How many schools in the dataset result in a `NULL` value for the `has_internet` field? This count represents the number of schools for which no digital resource report was found, a critical piece of information for resource allocation efforts under SDG 4.",
                "hint": "Mount `edu_data`. Run <code>SELECT s.school_name, dr.has_internet FROM Schools AS s LEFT JOIN DigitalResourceReports AS dr ON s.school_id = dr.school_id;</code> Count where `has_internet` is NULL.",
                "solution": "SELECT s.school_name, s.district, dr.has_internet FROM Schools AS s LEFT JOIN DigitalResourceReports AS dr ON s.school_id = dr.school_id ORDER BY s.district, s.school_name;",
                "difficulty": 2,
                "points": 125,
                "timeLimit": 300,
                "timerEnabled": false,
                "successMessage": "Perfect! LEFT JOIN showed all schools, clearly identifying those missing digital resource reports. This is crucial for SDG 4 resource allocation.",
                "dbAlias": "edu_data",
                "validationCriteria": {
                    "keywords": ["SELECT", "FROM", "Schools", "LEFT JOIN", "DigitalResourceReports", "ON"],
                    "mustContainColumns": ["school_name", "has_internet"],
                    "answerToQuestion": "2"
                },
                "mapDetails": {
                    "showOnMap": false
                },
                "nextMissionId": 104
            },
            {
                "id": 104,
                "title": "Aligning Skills & Economic Sectors (Multi-JOIN for SDGs 4 & 8)",
                "description": "Boss: Analyst #6023, to meaningfully impact their SDG 4 (Quality Education) and SDG 8 (Decent Work and Economic Growth), we need to help humans understand the intricate web connecting their economic sectors, the specific skills these sectors demand, and the training programs available to develop those skills. This necessitates joining multiple data tables to build a comprehensive picture.<br><br><strong>Part 1: Mapping Complex Relationships with Multi-Table JOINs</strong><br>You will now construct queries that link data across three or more tables, using a series of JOIN operations to trace relationships from broad economic sectors down to individual training initiatives.<br><br><strong>Your Directives:</strong><br>1. Access the DB REGISTRY and mount the <code>workforce_development_db</code> database (aliased as <code>skills_db</code>). This database links economic sectors, required skills, and training programs.<br>2. Your task is to create a query that synthesizes and calculates key metrics related to skill investment in a specific sector:<br><code>SELECT ski.skill_name, COUNT(tp.program_id) AS program_count, AVG(tp.duration_months) AS avg_duration,<br>ROUND(AVG(tp.cost_usd) / 1000, 1) AS avg_cost_thousands,<br>ROUND(ski.technical_complexity * ski.experience_years_avg, 1) AS complexity_score<br>FROM RequiredSkills AS ski<br>JOIN EconomicSectors AS sec ON ski.sector_id = sec.sector_id<br>LEFT JOIN TrainingPrograms AS tp ON ski.skill_id = tp.skill_id<br>WHERE sec.sector_name = 'Renewable Energy'<br>GROUP BY ski.skill_name<br>ORDER BY complexity_score DESC;</code><br><br>After executing this query, utilize the <strong>GRAPH</strong> button. The resulting data is ideal for a BAR CHART, which can visually compare calculated 'complexity_scores', counts of available 'programs', and average 'training costs' across the various skills within the 'Renewable Energy' sector. The <code>complexity_score</code> is a synthetic metric derived by multiplying the skill's technical complexity by the average years of experience typically required for it. This analysis will highlight areas of high demand, high complexity, and potentially under-resourced training.",
                "hint": "Access the DB REGISTRY and mount `skills_db`. Use: <code>SELECT ski.skill_name, COUNT(tp.program_id) AS program_count, AVG(tp.duration_months) AS avg_duration, ROUND(AVG(tp.cost_usd) / 1000, 1) AS avg_cost_thousands, ROUND(ski.technical_complexity * ski.experience_years_avg, 1) AS complexity_score FROM RequiredSkills AS ski JOIN EconomicSectors AS sec ON ski.sector_id = sec.sector_id LEFT JOIN TrainingPrograms AS tp ON ski.skill_id = tp.skill_id WHERE sec.sector_name = 'Renewable Energy' GROUP BY ski.skill_name ORDER BY complexity_score DESC;</code>",
                "solution": "SELECT ski.skill_name, COUNT(tp.program_id) AS program_count, AVG(tp.duration_months) AS avg_duration, ROUND(AVG(tp.cost_usd) / 1000, 1) AS avg_cost_thousands, ROUND(ski.technical_complexity * ski.experience_years_avg, 1) AS complexity_score FROM RequiredSkills AS ski JOIN EconomicSectors AS sec ON ski.sector_id = sec.sector_id LEFT JOIN TrainingPrograms AS tp ON ski.skill_id = tp.skill_id WHERE sec.sector_name = 'Renewable Energy' GROUP BY ski.skill_name ORDER BY complexity_score DESC;",
                "difficulty": 3,
                "points": 150,
                "timeLimit": 360,
                "timerEnabled": false,
                "successMessage": "Outstanding! You've mapped a complex relationship from economic sectors to specific skills and the training programs addressing them – vital for workforce development.",
                "dbAlias": "skills_db",
                "validationCriteria": {
                    "keywords": ["SELECT", "FROM", "RequiredSkills", "JOIN", "EconomicSectors", "ON", "LEFT JOIN", "TrainingPrograms", "ON", "WHERE", "GROUP BY", "COUNT", "AVG", "ROUND"],
                    "mustContainColumns": ["skill_name", "program_count", "complexity_score"],
                    "queryStructureChecks": [
                        {"checkType": "filter", "column": "sector_name", "expectedValue": "Renewable Energy"},
                        {"checkType": "aggregation", "function": "COUNT", "column": "tp.program_id"},
                        {"checkType": "aggregation", "function": "ROUND", "column": "ski.technical_complexity * ski.experience_years_avg"}
                    ],
                    "minRows": 1
                },
                "mapDetails": {
                    "showOnMap": false
                },
                "nextMissionId": 105
            },
            {
                "id": 105,
                "title": "Marine Protection Analysis (Aliases in JOINs for SDG 14)",
                "description": "Boss: Analyst #6023, we turn our attention to the planet's oceans, specifically focusing on SDG 14: Life Below Water. Analyzing data related to Marine Protected Areas (MPAs), species sightings within them, and recorded threats often involves complex queries joining multiple datasets. To maintain clarity in such intricate SQL commands, the use of 'table aliases' is paramount.<br><br><strong>Part 1: Enhancing Readability with Table Aliases</strong><br>Table aliases are temporary, shorter names assigned to tables within a query, significantly improving the readability and manageability of complex JOIN statements, especially when column names might be ambiguous across tables.<br><br><strong>Your Directives:</strong><br>1. Access the DB REGISTRY and mount the <code>ocean_guard_db</code> database (aliased as <code>marine_db</code>). This repository contains information on MPAs, species sightings, and environmental threats.<br>2. Your task is to construct a query that calculates a synthetic 'impact score' for various threats and counts these threats by type within critically endangered species habitats located in MPAs. Pay close attention to the use of aliases (e.g., `rt` for `RecordedThreats`).<br><code>SELECT rt.threat_type, COUNT(*) AS threat_count, SUM(rt.severity_level * rt.species_affected_count) AS impact_score<br>FROM RecordedThreats AS rt<br>JOIN MarineProtectedAreas AS mpa ON rt.mpa_id = mpa.mpa_id<br>JOIN EndangeredSpeciesSightings AS ess ON mpa.mpa_id = ess.mpa_id<br>WHERE rt.severity_level >= 4 AND ess.conservation_status = 'CriticallyEndangered'<br>GROUP BY rt.threat_type<br>ORDER BY impact_score DESC;</code><br><br>After running the query, use the <strong>GRAPH</strong> button. This type of numerical output lends itself well to a BAR or PIE chart, which can effectively display both the frequency of different threat types (<code>threat_count</code>) and their calculated severity (<code>impact_score</code>). The <code>impact_score</code> is calculated here by multiplying the threat's severity level by the number of species affected, providing a weighted measure of its detrimental effect. This targeted analysis helps prioritize which threats require the most urgent mitigation efforts within MPAs.",
                "hint": "Access the DB REGISTRY and mount `marine_db`. Use: <code>SELECT rt.threat_type, COUNT(*) AS threat_count, SUM(rt.severity_level * rt.species_affected_count) AS impact_score FROM RecordedThreats AS rt JOIN MarineProtectedAreas AS mpa ON rt.mpa_id = mpa.mpa_id JOIN EndangeredSpeciesSightings AS ess ON mpa.mpa_id = ess.mpa_id WHERE rt.severity_level >= 4 AND ess.conservation_status = 'CriticallyEndangered' GROUP BY rt.threat_type ORDER BY impact_score DESC;</code>",
                "solution": "SELECT rt.threat_type, COUNT(*) AS threat_count, SUM(rt.severity_level * rt.species_affected_count) AS impact_score FROM RecordedThreats AS rt JOIN MarineProtectedAreas AS mpa ON rt.mpa_id = mpa.mpa_id JOIN EndangeredSpeciesSightings AS ess ON mpa.mpa_id = ess.mpa_id WHERE rt.severity_level >= 4 AND ess.conservation_status = 'CriticallyEndangered' GROUP BY rt.threat_type ORDER BY impact_score DESC;",
                "difficulty": 3,
                "points": 150,
                "timeLimit": 360,
                "timerEnabled": false,
                "successMessage": "Well done! Table aliases made that multi-join query for marine protection analysis much clearer. This helps focus conservation efforts for SDG 14.",
                "dbAlias": "marine_db",
                "validationCriteria": {
                    "keywords": ["SELECT", "FROM", "RecordedThreats", "AS", "rt", "JOIN", "MarineProtectedAreas", "AS", "mpa", "JOIN", "EndangeredSpeciesSightings", "AS", "ess", "GROUP BY", "COUNT", "SUM"],
                    "mustContainColumns": ["threat_type", "threat_count", "impact_score"],
                    "queryStructureChecks": [
                        {"checkType": "filterLogic", "conditions": [{"column": "rt.severity_level", "operator": ">=", "expectedValue": 4}, {"column": "ess.conservation_status", "operator": "=", "expectedValue": "CriticallyEndangered"}]},
                        {"checkType": "aggregation", "function": "COUNT", "column": "*"},
                        {"checkType": "aggregation", "function": "SUM", "column": "rt.severity_level * rt.species_affected_count"}
                    ]
                },
                "mapDetails": {
                    "showOnMap": false
                },
                "nextMissionId": 106
            },
            {
                "id": 106,
                "title": "Education Investment & Outcomes (JOINs & GROUP BY for SDG 4)",
                "description": "Boss: Analyst #6023, returning to SDG 4 (Quality Education), a critical question for human policymakers is whether regional financial investment in education correlates with improved student performance metrics. To investigate this, you will need to JOIN data from educational finance tables with student performance tables and then use GROUP BY to aggregate insights at a regional level.<br><br><strong>Part 1: Deriving Insights by Aggregating Joined Datasets</strong><br>This mission requires you to link disparate datasets and then summarize the combined information to reveal higher-level trends or correlations, a common analytical pattern in socioeconomic research.<br><br><strong>Your Directives:</strong><br>1. Access the DB REGISTRY and mount the <code>edu_finance_performance_db</code> (aliased as <code>edu_stats_db</code>). This archive holds regional education investment figures and corresponding student performance data.<br>2. Your goal is to construct a query that correlates regional education investment levels with average student test scores for a specific year:<br><code>SELECT rei.region_name, rei.annual_investment_usd_avg, AVG(spm.avg_test_score) AS average_regional_test_score<br>FROM RegionalEducationInvestment AS rei<br>JOIN StudentPerformanceMetrics AS spm ON rei.region_id = spm.region_id<br>WHERE rei.year_recorded = 2023 AND spm.year_recorded = 2023<br>GROUP BY rei.region_name, rei.annual_investment_usd_avg<br>ORDER BY rei.annual_investment_usd_avg DESC;</code><br><br>After executing, utilize the <strong>GRAPH</strong> button. For this type of correlational analysis, a SCATTER PLOT is the most suitable visualization. You would typically plot <code>annual_investment_usd_avg</code> on the X-axis and <code>average_regional_test_score</code> on the Y-axis. This allows for visual identification of any trends suggesting whether higher investment aligns with higher test scores. Such insights are vital for guiding resource allocation strategies within their education sector under SDG 4.",
                "hint": "Mount `edu_stats_db`. Use query: <code>SELECT rei.region_name, rei.annual_investment_usd_avg, AVG(spm.avg_test_score) AS avg_score FROM RegionalEducationInvestment AS rei JOIN StudentPerformanceMetrics AS spm ON rei.region_id = spm.region_id WHERE rei.year_recorded = 2023 AND spm.year_recorded = 2023 GROUP BY rei.region_name, rei.annual_investment_usd_avg ORDER BY rei.annual_investment_usd_avg DESC;</code> Then use Scatter Plot.",
                "solution": "SELECT rei.region_name, rei.annual_investment_usd_avg, AVG(spm.avg_test_score) AS average_regional_test_score FROM RegionalEducationInvestment AS rei JOIN StudentPerformanceMetrics AS spm ON rei.region_id = spm.region_id WHERE rei.year_recorded = 2023 AND spm.year_recorded = 2023 GROUP BY rei.region_name, rei.annual_investment_usd_avg ORDER BY rei.annual_investment_usd_avg DESC;",
                "difficulty": 3,
                "points": 175,
                "timeLimit": 360,
                "timerEnabled": false,
                "successMessage": "Excellent! You've combined JOINs with GROUP BY and AVG to analyze the relationship between education funding and outcomes, vital for SDG 4 strategies.",
                "dbAlias": "edu_stats_db",
                "validationCriteria": {
                    "keywords": ["SELECT", "AVG", "FROM", "RegionalEducationInvestment", "JOIN", "StudentPerformanceMetrics", "ON", "GROUP BY", "ORDER BY"],
                    "mustContainColumns": ["region_name", "annual_investment_usd_avg", "average_regional_test_score"],
                    "aggregation": true,
                    "groupBy": ["region_name", "annual_investment_usd_avg"],
                    "ordered": true
                },
                "mapDetails": {
                    "showOnMap": false
                },
                "nextMissionId": 107
            },
            {
                "id": 107,
                "title": "Coastal City Sustainability & Marine Health (Filtered JOINs, SDGs 11 & 14)",
                "description": "Boss: Analyst #6023, this is your final analytical mission for this planetary assignment. It's a complex one, designed to assess the nuanced interdependencies between coastal urban development (SDG 11: Sustainable Cities and Communities) and the health of adjacent marine ecosystems (SDG 14: Life Below Water). Success here requires leveraging your full SQL repertoire: advanced JOINs, precise filtering, and meaningful data aggregation, culminating in visualization.<br><br><strong>Part 1: Conducting Comprehensive Environmental Impact Analysis</strong><br>You will integrate data from coastal city development projects with marine health indicators to identify potential relationships and areas of concern.<br><br><strong>Your Directives:</strong><br>1. Access the DB REGISTRY and mount the <code>coastal_eco_impact_db</code> database (aliased as <code>coast_health_db</code>). This archive links urban projects in coastal cities to marine environmental data.<br>2. Your task is to construct a query that analyzes the relationship between a city's investment in 'WasteManagement' projects and the measured 'CoralReefHealthIndex' in its proximate marine environment, under specific conditions:<br><code>SELECT cc.city_name, SUM(sp.investment_mio_usd) AS total_waste_mgmt_investment, AVG(mei.indicator_value) AS avg_coral_health_index<br>FROM CoastalCities AS cc<br>JOIN SustainableProjects AS sp ON cc.city_id = sp.city_id<br>JOIN MarineEcosystemIndicators AS mei ON cc.city_id = mei.city_id<br>WHERE sp.project_category = 'WasteManagement' AND mei.indicator_name = 'CoralReefHealthIndex' AND sp.year_implemented >= 2020<br>GROUP BY cc.city_name<br>HAVING COUNT(sp.project_id) >= 2  -- Consider only cities with at least 2 significant waste management projects post-2020<br>ORDER BY avg_coral_health_index DESC;</code><br><br>Upon query execution, utilize the <strong>GRAPH</strong> button. A SCATTER PLOT or a detailed BAR chart could effectively display the `total_waste_mgmt_investment` in millions of USD against the `avg_coral_health_index` for the selected coastal cities. This will help visualize if increased investment in waste management by cities with multiple recent projects correlates with better coral health, providing crucial data for their sustainable development policies concerning SDGs 11 and 14.",
                "hint": "Mount `coast_health_db`. Use the detailed query provided. Key elements are multiple JOINs, WHERE filters for project type and indicator, GROUP BY city, and a HAVING clause. Then visualize with Scatter or Bar chart.",
                "solution": "SELECT cc.city_name, SUM(sp.investment_mio_usd) AS total_waste_mgmt_investment, AVG(mei.indicator_value) AS avg_coral_health_index FROM CoastalCities AS cc JOIN SustainableProjects AS sp ON cc.city_id = sp.city_id JOIN MarineEcosystemIndicators AS mei ON cc.city_id = mei.city_id WHERE sp.project_category = 'WasteManagement' AND mei.indicator_name = 'CoralReefHealthIndex' AND sp.year_implemented >= 2020 GROUP BY cc.city_name HAVING COUNT(sp.project_id) >= 2 ORDER BY avg_coral_health_index DESC;",
                "difficulty": 4,
                "points": 200,
                "timeLimit": 420,
                "timerEnabled": false,
                "successMessage": "Analyst #6023, your work here has been exemplary. You've not only deciphered human data systems but have actively contributed to their planetary well-being by assisting with their 'Sustainable Development Goals'. Your reports have provided critical insights. It's time to return. Your mission aiding the humans is complete, and exceptionally well done. Prepare for debriefing upon your arrival back home.",
                "dbAlias": "coast_health_db",
                "validationCriteria": {
                    "keywords": ["SELECT", "SUM", "AVG", "FROM", "CoastalCities", "JOIN", "SustainableProjects", "ON", "JOIN", "MarineEcosystemIndicators", "ON", "WHERE", "GROUP BY", "HAVING", "ORDER BY"],
                    "mustContainColumns": ["city_name", "total_waste_mgmt_investment", "avg__coral_health_index"],
                    "aggregation": true,
                    "groupBy": ["city_name"],
                    "queryStructureChecks": [
                        {"checkType": "filterLogic", "conditions": [
                            {"column": "sp.project_category", "expectedValue": "WasteManagement"},
                            {"column": "mei.indicator_name", "expectedValue": "CoralReefHealthIndex"},
                            {"column": "sp.year_implemented", "operator": ">=", "expectedValue": 2020}
                        ]}
                    ],
                    "havingClauseCheck": {"aggregateFunction": "COUNT", "column": "sp.project_id", "operator": ">=", "value": 2},
                    "ordered": true
                },
                "mapDetails": {
                    "showOnMap": false
                }
            }
        ]
    }
}